1) По модулям не разносил. Сделал копипастом несколько файлов, в каждом из которых
   отличается несколько строк в одной функции main, чтобы все было перед глазами.
2) Делал на основе SuperJob, потому что данных меньше и отдает более стабильно
   (три файла: task_3_1_...), поэтому проще отслеживать.
   Но приложил файл и с реализацией для HH.ru (task_3_2_hh.py).
3) Две базы данных vacancies_hh и vacancies_sj соответственно. В них создаются коллекции
   по имени запроса. В моем случае Python.
4) Не знаю насколько правильно, обновление данных делал тремя способами:
   - insert_one() с использованием DuplicateKeyError;
   - insert_one() с использованием индексов;
   - update_one().
5) Курсы валют для сортировки по зарплате качаю с ЦБ, иногда их сайт подводит.
   find_by_salary() - отбор по зарплате;
   get_rate() - выбор курса.


Вопросы:
1) Насколько влияет на скорость использование индексов? При записи и при считывании.
   В том смысле, что нужно ли их применять при использовании update?
2) При повторном парсинге выбрасывает исключение 'Duplicate key error collection'.
   Почему не понял. Mongo же не может присвоить тот же id новому документу, хоть
   данные и повторяются.
   Когда использую индексы, отключал try и проверял - исключение формируется в том числе
   и на основе совпадения индексов.
   А когда не используются индексы, откуда дублирование ключей?
3) Пробовал данные из mongo перегнать в json, ругается на недопустимый формат.
   Показалось странным. Что не так?
